{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-07-26T16:17:57.985024Z","iopub.status.busy":"2024-07-26T16:17:57.984753Z","iopub.status.idle":"2024-07-26T16:18:12.987914Z","shell.execute_reply":"2024-07-26T16:18:12.987135Z","shell.execute_reply.started":"2024-07-26T16:17:57.985001Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-07-26 16:18:00.240809: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-07-26 16:18:00.240927: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-07-26 16:18:00.408141: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["import tensorflow as tf                                \n","import matplotlib.pyplot as plt                                         \n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam         \n","from tensorflow.keras.callbacks import EarlyStopping   \n","from tensorflow.keras.regularizers import l1, l2      \n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.layers import Dense, Flatten, Dropout,BatchNormalization  \n","from tensorflow.keras.applications import DenseNet121"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-07-26T16:18:12.990488Z","iopub.status.busy":"2024-07-26T16:18:12.989745Z","iopub.status.idle":"2024-07-26T16:18:15.819328Z","shell.execute_reply":"2024-07-26T16:18:15.818565Z","shell.execute_reply.started":"2024-07-26T16:18:12.990454Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 1215 files belonging to 4 classes.\n"]}],"source":["train_data = tf.keras.utils.image_dataset_from_directory(\n","    \"/kaggle/input/soil-types-dataset/Dataset/Train\",\n","    labels='inferred',\n","    label_mode='categorical',\n","    image_size=(256, 256),\n","    batch_size=32)\n","\n","train_data = train_data.map(lambda x, y: (x / 255.0, y))"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-07-26T16:18:41.279680Z","iopub.status.busy":"2024-07-26T16:18:41.279258Z","iopub.status.idle":"2024-07-26T16:18:41.420738Z","shell.execute_reply":"2024-07-26T16:18:41.420082Z","shell.execute_reply.started":"2024-07-26T16:18:41.279649Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 340 files belonging to 4 classes.\n"]}],"source":["val_data = tf.keras.preprocessing.image_dataset_from_directory(\n","    \"/kaggle/input/soil-types-dataset/Dataset/test\",\n","    labels='inferred',\n","    label_mode='categorical',\n","    image_size=(256, 256),\n","    batch_size=32)\n","\n","val_data = val_data.map(lambda x, y: (x / 255.0, y))"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-07-26T16:18:43.599518Z","iopub.status.busy":"2024-07-26T16:18:43.599156Z","iopub.status.idle":"2024-07-26T16:18:45.522288Z","shell.execute_reply":"2024-07-26T16:18:45.521324Z","shell.execute_reply.started":"2024-07-26T16:18:43.599490Z"},"trusted":true},"outputs":[],"source":["conv = DenseNet121(\n","    weights='imagenet',\n","    include_top = False,\n","    input_shape=(256,256,3),\n","    pooling='avg'\n",")"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-07-26T16:18:47.920885Z","iopub.status.busy":"2024-07-26T16:18:47.920172Z","iopub.status.idle":"2024-07-26T16:18:47.935606Z","shell.execute_reply":"2024-07-26T16:18:47.934191Z","shell.execute_reply.started":"2024-07-26T16:18:47.920849Z"},"trusted":true},"outputs":[],"source":["conv.trainable = False"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-07-26T16:18:49.627714Z","iopub.status.busy":"2024-07-26T16:18:49.627312Z","iopub.status.idle":"2024-07-26T16:18:49.645573Z","shell.execute_reply":"2024-07-26T16:18:49.644604Z","shell.execute_reply.started":"2024-07-26T16:18:49.627684Z"},"trusted":true},"outputs":[],"source":["model = Sequential()\n","model.add(conv)\n","model.add(BatchNormalization())\n","model.add(Flatten())\n","model.add(Dense(256, activation='relu'))\n","model.add(Dropout(0.3))\n","model.add(BatchNormalization())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(4, activation='softmax'))"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-07-26T16:18:52.921535Z","iopub.status.busy":"2024-07-26T16:18:52.920706Z","iopub.status.idle":"2024-07-26T16:18:52.937238Z","shell.execute_reply":"2024-07-26T16:18:52.936503Z","shell.execute_reply.started":"2024-07-26T16:18:52.921501Z"},"trusted":true},"outputs":[],"source":["model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-07-26T16:19:06.418878Z","iopub.status.busy":"2024-07-26T16:19:06.418102Z","iopub.status.idle":"2024-07-26T16:22:44.203311Z","shell.execute_reply":"2024-07-26T16:22:44.202377Z","shell.execute_reply.started":"2024-07-26T16:19:06.418841Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1722010786.859238      93 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","W0000 00:00:1722010786.928579      93 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","W0000 00:00:1722010814.934198      91 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","W0000 00:00:1722010824.943188      91 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["38/38 - 97s - 3s/step - accuracy: 0.5160 - loss: 1.1446 - val_accuracy: 0.6206 - val_loss: 1.1376\n","Epoch 2/100\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1722010843.473070      91 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["38/38 - 5s - 119ms/step - accuracy: 0.7770 - loss: 0.6490 - val_accuracy: 0.7441 - val_loss: 0.9448\n","Epoch 3/100\n","38/38 - 4s - 116ms/step - accuracy: 0.8502 - loss: 0.4763 - val_accuracy: 0.8088 - val_loss: 0.7812\n","Epoch 4/100\n","38/38 - 4s - 116ms/step - accuracy: 0.8864 - loss: 0.3831 - val_accuracy: 0.8559 - val_loss: 0.6190\n","Epoch 5/100\n","38/38 - 4s - 118ms/step - accuracy: 0.8971 - loss: 0.3191 - val_accuracy: 0.9059 - val_loss: 0.4973\n","Epoch 6/100\n","38/38 - 4s - 118ms/step - accuracy: 0.9267 - loss: 0.2682 - val_accuracy: 0.9294 - val_loss: 0.3929\n","Epoch 7/100\n","38/38 - 5s - 125ms/step - accuracy: 0.9432 - loss: 0.2286 - val_accuracy: 0.9412 - val_loss: 0.3142\n","Epoch 8/100\n","38/38 - 5s - 120ms/step - accuracy: 0.9473 - loss: 0.1968 - val_accuracy: 0.9500 - val_loss: 0.2527\n","Epoch 9/100\n","38/38 - 5s - 120ms/step - accuracy: 0.9440 - loss: 0.1870 - val_accuracy: 0.9647 - val_loss: 0.2060\n","Epoch 10/100\n","38/38 - 5s - 121ms/step - accuracy: 0.9605 - loss: 0.1602 - val_accuracy: 0.9735 - val_loss: 0.1694\n","Epoch 11/100\n","38/38 - 5s - 122ms/step - accuracy: 0.9580 - loss: 0.1430 - val_accuracy: 0.9735 - val_loss: 0.1414\n","Epoch 12/100\n","38/38 - 5s - 136ms/step - accuracy: 0.9597 - loss: 0.1379 - val_accuracy: 0.9765 - val_loss: 0.1179\n","Epoch 13/100\n","38/38 - 5s - 124ms/step - accuracy: 0.9695 - loss: 0.1159 - val_accuracy: 0.9824 - val_loss: 0.0987\n","Epoch 14/100\n","38/38 - 5s - 125ms/step - accuracy: 0.9720 - loss: 0.1075 - val_accuracy: 0.9824 - val_loss: 0.0819\n","Epoch 15/100\n","38/38 - 5s - 121ms/step - accuracy: 0.9745 - loss: 0.0947 - val_accuracy: 0.9882 - val_loss: 0.0714\n","Epoch 16/100\n","38/38 - 5s - 123ms/step - accuracy: 0.9802 - loss: 0.0980 - val_accuracy: 0.9882 - val_loss: 0.0598\n","Epoch 17/100\n","38/38 - 5s - 121ms/step - accuracy: 0.9819 - loss: 0.0794 - val_accuracy: 0.9882 - val_loss: 0.0527\n","Epoch 18/100\n","38/38 - 5s - 122ms/step - accuracy: 0.9811 - loss: 0.0821 - val_accuracy: 0.9912 - val_loss: 0.0484\n","Epoch 19/100\n","38/38 - 5s - 134ms/step - accuracy: 0.9835 - loss: 0.0745 - val_accuracy: 0.9912 - val_loss: 0.0419\n","Epoch 20/100\n","38/38 - 5s - 122ms/step - accuracy: 0.9811 - loss: 0.0722 - val_accuracy: 0.9912 - val_loss: 0.0373\n","Epoch 21/100\n","38/38 - 5s - 133ms/step - accuracy: 0.9877 - loss: 0.0636 - val_accuracy: 0.9882 - val_loss: 0.0339\n","Epoch 22/100\n","38/38 - 5s - 118ms/step - accuracy: 0.9868 - loss: 0.0592 - val_accuracy: 0.9941 - val_loss: 0.0312\n","Epoch 23/100\n","38/38 - 5s - 119ms/step - accuracy: 0.9885 - loss: 0.0544 - val_accuracy: 0.9971 - val_loss: 0.0272\n","Epoch 24/100\n","38/38 - 4s - 118ms/step - accuracy: 0.9901 - loss: 0.0494 - val_accuracy: 0.9971 - val_loss: 0.0253\n","Epoch 25/100\n","38/38 - 5s - 119ms/step - accuracy: 0.9901 - loss: 0.0537 - val_accuracy: 0.9971 - val_loss: 0.0217\n","Epoch 26/100\n","38/38 - 4s - 118ms/step - accuracy: 0.9885 - loss: 0.0487 - val_accuracy: 0.9971 - val_loss: 0.0215\n","Epoch 27/100\n","38/38 - 5s - 126ms/step - accuracy: 0.9909 - loss: 0.0423 - val_accuracy: 0.9971 - val_loss: 0.0220\n"]}],"source":["history = model.fit(train_data, epochs=100, validation_data=val_data, callbacks=[EarlyStopping(patience=0)], verbose=2)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-07-26T16:22:44.205452Z","iopub.status.busy":"2024-07-26T16:22:44.205109Z","iopub.status.idle":"2024-07-26T16:22:45.275379Z","shell.execute_reply":"2024-07-26T16:22:45.274497Z","shell.execute_reply.started":"2024-07-26T16:22:44.205426Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.9992 - loss: 0.0207\n","Validation Loss: 0.02202850766479969\n","Validation Accuracy: 0.9970588088035583\n"]}],"source":["evaluation = model.evaluate(val_data)\n","print(\"Validation Loss:\", evaluation[0])\n","print(\"Validation Accuracy:\", evaluation[1])"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"A total of 5 objects could not be loaded. Example error message for object <BatchNormalization name=batch_normalization_26, built=False>:\n\nLayer 'batch_normalization_26' was never built and thus it doesn't have any variables. However the weights file lists 4 variables for this layer.\nIn most cases, this error indicates that either:\n\n1. The layer is owned by a parent layer that implements a `build()` method, but calling the parent's `build()` method did NOT create the state of the child layer 'batch_normalization_26'. A `build()` method must create ALL state for the layer, including the state of any children layers.\n\n2. You need to implement the `def build_from_config(self, config)` method on layer 'batch_normalization_26', to specify how to rebuild it during loading. In this case, you might also want to implement the method that generates the build config at saving time, `def get_build_config(self)`. The method `build_from_config()` is meant to create the state of the layer (i.e. its variables) upon deserialization.\n\nList of objects that could not be loaded:\n[<BatchNormalization name=batch_normalization_26, built=False>, <Dense name=dense_39, built=False>, <BatchNormalization name=batch_normalization_27, built=False>, <Dense name=dense_40, built=False>, <Dense name=dense_41, built=False>]","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[16], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m model \u001b[38;5;241m=\u001b[39m create_model()\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Load the model weights\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mAtharva Bhattad\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDownloads\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mClassification\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mmy_soil_model.weights.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Load and preprocess the test image\u001b[39;00m\n\u001b[0;32m     32\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAtharva Bhattad\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124marchive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSoil types\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mBlack Soil\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m2.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Update this path\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\Atharva Bhattad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[1;32mc:\\Users\\Atharva Bhattad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:456\u001b[0m, in \u001b[0;36m_raise_loading_failure\u001b[1;34m(error_msgs, warn_only)\u001b[0m\n\u001b[0;32m    454\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg)\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n","\u001b[1;31mValueError\u001b[0m: A total of 5 objects could not be loaded. Example error message for object <BatchNormalization name=batch_normalization_26, built=False>:\n\nLayer 'batch_normalization_26' was never built and thus it doesn't have any variables. However the weights file lists 4 variables for this layer.\nIn most cases, this error indicates that either:\n\n1. The layer is owned by a parent layer that implements a `build()` method, but calling the parent's `build()` method did NOT create the state of the child layer 'batch_normalization_26'. A `build()` method must create ALL state for the layer, including the state of any children layers.\n\n2. You need to implement the `def build_from_config(self, config)` method on layer 'batch_normalization_26', to specify how to rebuild it during loading. In this case, you might also want to implement the method that generates the build config at saving time, `def get_build_config(self)`. The method `build_from_config()` is meant to create the state of the layer (i.e. its variables) upon deserialization.\n\nList of objects that could not be loaded:\n[<BatchNormalization name=batch_normalization_26, built=False>, <Dense name=dense_39, built=False>, <BatchNormalization name=batch_normalization_27, built=False>, <Dense name=dense_40, built=False>, <Dense name=dense_41, built=False>]"]}],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.applications import DenseNet121\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, BatchNormalization, Flatten, Dense, Dropout\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Define the DenseNet-based model architecture\n","def create_model():\n","    conv = DenseNet121(weights='imagenet', include_top=False, input_shape=(256, 256, 3), pooling='avg')\n","    \n","    model = Sequential()\n","    model.add(conv)\n","    model.add(BatchNormalization())\n","    model.add(Flatten())\n","    model.add(Dense(256, activation='relu'))\n","    model.add(Dropout(0.3))\n","    model.add(BatchNormalization())\n","    model.add(Dense(128, activation='relu'))\n","    model.add(Dense(4, activation='softmax')) # Adjust the number of classes accordingly\n","    \n","    return model\n","\n","# Create the model\n","model = create_model()\n","\n","# Build the model (important for initializing the layers)\n","model.build(input_shape=(None, 256, 256, 3))\n","\n","# Load the model weights\n","model.load_weights(r\"C:\\Users\\Atharva Bhattad\\Downloads\\Classification\\my_soil_model.weights.h5\")\n","\n","# Prepare the test data\n","\n","# test_datagen = ImageDataGenerator(rescale=1./255)\n","test_data = tf.keras.preprocessing.image_dataset_from_directory(\n","    r\"C:\\Users\\Atharva Bhattad\\Downloads\\archive\\Soil types\\Black Soil\\2.jpg\",  # Update this path\n","    image_size=(256, 256),\n","    batch_size=1,\n","    label_mode='categorical',\n","    shuffle=False)\n","test_data = test_data.map(lambda x, y: (x / 255.0, y))\n","\n","class_name = ['Alluvial soil','Black Soil','Clay soil','Red soil']\n","# Predict using the model\n","# Predict using the model\n","predictions = model.predict(test_data)\n","\n","# Convert predictions to class labels (indices)\n","predicted_classes = np.argmax(predictions, axis=1)\n","\n","# Map predicted class indices to class names\n","predicted_class_names = [class_name[idx] for idx in predicted_classes]\n","\n","# Print predicted class names\n","print(predicted_class_names)\n","\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Error loading weights: A total of 5 objects could not be loaded. Example error message for object <BatchNormalization name=batch_normalization_28, built=False>:\n","\n","Layer 'batch_normalization_28' was never built and thus it doesn't have any variables. However the weights file lists 4 variables for this layer.\n","In most cases, this error indicates that either:\n","\n","1. The layer is owned by a parent layer that implements a `build()` method, but calling the parent's `build()` method did NOT create the state of the child layer 'batch_normalization_28'. A `build()` method must create ALL state for the layer, including the state of any children layers.\n","\n","2. You need to implement the `def build_from_config(self, config)` method on layer 'batch_normalization_28', to specify how to rebuild it during loading. In this case, you might also want to implement the method that generates the build config at saving time, `def get_build_config(self)`. The method `build_from_config()` is meant to create the state of the layer (i.e. its variables) upon deserialization.\n","\n","List of objects that could not be loaded:\n","[<BatchNormalization name=batch_normalization_28, built=False>, <Dense name=dense_42, built=False>, <BatchNormalization name=batch_normalization_29, built=False>, <Dense name=dense_43, built=False>, <Dense name=dense_44, built=False>]\n","Image loaded and preprocessed successfully.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n","Prediction made successfully.\n","Predicted class indices: [2]\n","Predicted class names: ['Clay soil']\n"]}],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.applications import DenseNet121\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import BatchNormalization, Flatten, Dense, Dropout\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.preprocessing.image import img_to_array\n","\n","# Define the DenseNet-based model architecture\n","def create_model():\n","    conv = DenseNet121(weights='imagenet', include_top=False, input_shape=(256, 256, 3), pooling='avg')\n","    \n","    model = Sequential()\n","    model.add(conv)\n","    model.add(BatchNormalization())\n","    model.add(Flatten())\n","    model.add(Dense(256, activation='relu'))\n","    model.add(Dropout(0.3))\n","    model.add(BatchNormalization())\n","    model.add(Dense(128, activation='relu'))\n","    model.add(Dense(4, activation='softmax'))  # Ensure this matches the number of classes in your weights\n","    \n","    return model\n","\n","# Create the model\n","model = create_model()\n","\n","# Load the model weights\n","try:\n","    model.load_weights(r\"C:\\Users\\Atharva Bhattad\\Downloads\\Classification\\my_soil_model.weights.h5\")\n","    print(\"Weights loaded successfully.\")\n","except Exception as e:\n","    print(f\"Error loading weights: {e}\")\n","\n","# Load and preprocess the test image\n","image_path = r\"C:\\Users\\Atharva Bhattad\\Downloads\\archive\\Soil types\\Black Soil\\2.jpg\"  # Update this path\n","try:\n","    img = image.load_img(image_path, target_size=(256, 256))\n","    img_array = img_to_array(img) / 255.0  # Normalize the image\n","    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n","    print(\"Image loaded and preprocessed successfully.\")\n","except Exception as e:\n","    print(f\"Error loading or preprocessing image: {e}\")\n","\n","# Predict using the model\n","try:\n","    predictions = model.predict(img_array)\n","    print(\"Prediction made successfully.\")\n","except Exception as e:\n","    print(f\"Error during prediction: {e}\")\n","\n","# Convert predictions to class labels (indices)\n","predicted_classes = np.argmax(predictions, axis=1)\n","print(f\"Predicted class indices: {predicted_classes}\")\n","\n","# Define class names\n","class_name = ['Alluvial soil', 'Black Soil', 'Clay soil', 'Red soil']\n","\n","# Map predicted class indices to class names\n","try:\n","    predicted_class_names = [class_name[idx] for idx in predicted_classes]\n","    print(f\"Predicted class names: {predicted_class_names}\")\n","except IndexError as e:\n","    print(f\"Error mapping class indices to names: {e}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":2499833,"sourceId":4241584,"sourceType":"datasetVersion"},{"datasetId":3653989,"sourceId":6345760,"sourceType":"datasetVersion"}],"dockerImageVersionId":30746,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":4}
